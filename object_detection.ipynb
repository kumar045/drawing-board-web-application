{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "object.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPuCMSlpEAu5VKF+nQUGtx0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kumar045/drawing-board-web-application/blob/master/object_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gD1-7NIOv_sR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"YOLO_v3 Model Defined in Keras.\"\"\"\n",
        "\n",
        "from functools import wraps\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras.layers import Conv2D, Add, ZeroPadding2D, UpSampling2D, Concatenate, MaxPooling2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.regularizers import l2\n",
        "\n",
        "from utils import compose\n",
        "\n",
        "\n",
        "@wraps(Conv2D)\n",
        "def DarknetConv2D(*args, **kwargs):\n",
        "    \"\"\"Wrapper to set Darknet parameters for Convolution2D.\"\"\"\n",
        "    darknet_conv_kwargs = {'kernel_regularizer': l2(5e-4)}\n",
        "    darknet_conv_kwargs['padding'] = 'valid' if kwargs.get('strides')==(2,2) else 'same'\n",
        "    darknet_conv_kwargs.update(kwargs)\n",
        "    return Conv2D(*args, **darknet_conv_kwargs)\n",
        "\n",
        "def DarknetConv2D_BN_Leaky(*args, **kwargs):\n",
        "    \"\"\"Darknet Convolution2D followed by BatchNormalization and LeakyReLU.\"\"\"\n",
        "    no_bias_kwargs = {'use_bias': False}\n",
        "    no_bias_kwargs.update(kwargs)\n",
        "    return compose(\n",
        "        DarknetConv2D(*args, **no_bias_kwargs),\n",
        "        BatchNormalization(),\n",
        "        LeakyReLU(alpha=0.1))\n",
        "\n",
        "def resblock_body(x, num_filters, num_blocks):\n",
        "    '''A series of resblocks starting with a downsampling Convolution2D'''\n",
        "    # Darknet uses left and top padding instead of 'same' mode\n",
        "    x = ZeroPadding2D(((1,0),(1,0)))(x)\n",
        "    x = DarknetConv2D_BN_Leaky(num_filters, (3,3), strides=(2,2))(x)\n",
        "    for i in range(num_blocks):\n",
        "        y = compose(\n",
        "                DarknetConv2D_BN_Leaky(num_filters//2, (1,1)),\n",
        "                DarknetConv2D_BN_Leaky(num_filters, (3,3)))(x)\n",
        "        x = Add()([x,y])\n",
        "    return x\n",
        "\n",
        "def darknet_body(x):\n",
        "    '''Darknent body having 52 Convolution2D layers'''\n",
        "    x = DarknetConv2D_BN_Leaky(32, (3,3))(x)\n",
        "    x = resblock_body(x, 64, 1)\n",
        "    x = resblock_body(x, 128, 2)\n",
        "    x = resblock_body(x, 256, 8)\n",
        "    x = resblock_body(x, 512, 8)\n",
        "    x = resblock_body(x, 1024, 4)\n",
        "    return x\n",
        "\n",
        "def make_last_layers(x, num_filters, out_filters):\n",
        "    '''6 Conv2D_BN_Leaky layers followed by a Conv2D_linear layer'''\n",
        "    x = compose(\n",
        "            DarknetConv2D_BN_Leaky(num_filters, (1,1)),\n",
        "            DarknetConv2D_BN_Leaky(num_filters*2, (3,3)),\n",
        "            DarknetConv2D_BN_Leaky(num_filters, (1,1)),\n",
        "            DarknetConv2D_BN_Leaky(num_filters*2, (3,3)),\n",
        "            DarknetConv2D_BN_Leaky(num_filters, (1,1)))(x)\n",
        "    y = compose(\n",
        "            DarknetConv2D_BN_Leaky(num_filters*2, (3,3)),\n",
        "            DarknetConv2D(out_filters, (1,1)))(x)\n",
        "    return x, y\n",
        "\n",
        "\n",
        "def yolo_body(inputs, num_anchors, num_classes):\n",
        "    \"\"\"Create YOLO_V3 model CNN body in Keras.\"\"\"\n",
        "    darknet = Model(inputs, darknet_body(inputs))\n",
        "    x, y1 = make_last_layers(darknet.output, 512, num_anchors*(num_classes+5))\n",
        "\n",
        "    x = compose(\n",
        "            DarknetConv2D_BN_Leaky(256, (1,1)),\n",
        "            UpSampling2D(2))(x)\n",
        "    x = Concatenate()([x,darknet.layers[152].output])\n",
        "    x, y2 = make_last_layers(x, 256, num_anchors*(num_classes+5))\n",
        "\n",
        "    x = compose(\n",
        "            DarknetConv2D_BN_Leaky(128, (1,1)),\n",
        "            UpSampling2D(2))(x)\n",
        "    x = Concatenate()([x,darknet.layers[92].output])\n",
        "    x, y3 = make_last_layers(x, 128, num_anchors*(num_classes+5))\n",
        "\n",
        "    return Model(inputs, [y1,y2,y3])\n",
        "\n",
        "def tiny_yolo_body(inputs, num_anchors, num_classes):\n",
        "    '''Create Tiny YOLO_v3 model CNN body in keras.'''\n",
        "    x1 = compose(\n",
        "            DarknetConv2D_BN_Leaky(16, (3,3)),\n",
        "            MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'),\n",
        "            DarknetConv2D_BN_Leaky(32, (3,3)),\n",
        "            MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'),\n",
        "            DarknetConv2D_BN_Leaky(64, (3,3)),\n",
        "            MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'),\n",
        "            DarknetConv2D_BN_Leaky(128, (3,3)),\n",
        "            MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'),\n",
        "            DarknetConv2D_BN_Leaky(256, (3,3)))(inputs)\n",
        "    x2 = compose(\n",
        "            MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'),\n",
        "            DarknetConv2D_BN_Leaky(512, (3,3)),\n",
        "            MaxPooling2D(pool_size=(2,2), strides=(1,1), padding='same'),\n",
        "            DarknetConv2D_BN_Leaky(1024, (3,3)),\n",
        "            DarknetConv2D_BN_Leaky(256, (1,1)))(x1)\n",
        "    y1 = compose(\n",
        "            DarknetConv2D_BN_Leaky(512, (3,3)),\n",
        "            DarknetConv2D(num_anchors*(num_classes+5), (1,1)))(x2)\n",
        "\n",
        "    x2 = compose(\n",
        "            DarknetConv2D_BN_Leaky(128, (1,1)),\n",
        "            UpSampling2D(2))(x2)\n",
        "    y2 = compose(\n",
        "            Concatenate(),\n",
        "            DarknetConv2D_BN_Leaky(256, (3,3)),\n",
        "            DarknetConv2D(num_anchors*(num_classes+5), (1,1)))([x2,x1])\n",
        "\n",
        "    return Model(inputs, [y1,y2])\n",
        "\n",
        "\n",
        "def yolo_head(feats, anchors, num_classes, input_shape, calc_loss=False):\n",
        "    \"\"\"Convert final layer features to bounding box parameters.\"\"\"\n",
        "    num_anchors = len(anchors)\n",
        "    # Reshape to batch, height, width, num_anchors, box_params.\n",
        "    anchors_tensor = K.reshape(K.constant(anchors), [1, 1, 1, num_anchors, 2])\n",
        "\n",
        "    grid_shape = K.shape(feats)[1:3] # height, width\n",
        "    grid_y = K.tile(K.reshape(K.arange(0, stop=grid_shape[0]), [-1, 1, 1, 1]),\n",
        "        [1, grid_shape[1], 1, 1])\n",
        "    grid_x = K.tile(K.reshape(K.arange(0, stop=grid_shape[1]), [1, -1, 1, 1]),\n",
        "        [grid_shape[0], 1, 1, 1])\n",
        "    grid = K.concatenate([grid_x, grid_y])\n",
        "    grid = K.cast(grid, K.dtype(feats))\n",
        "\n",
        "    feats = K.reshape(\n",
        "        feats, [-1, grid_shape[0], grid_shape[1], num_anchors, num_classes + 5])\n",
        "\n",
        "    # Adjust preditions to each spatial grid point and anchor size.\n",
        "    box_xy = (K.sigmoid(feats[..., :2]) + grid) / K.cast(grid_shape[::-1], K.dtype(feats))\n",
        "    box_wh = K.exp(feats[..., 2:4]) * anchors_tensor / K.cast(input_shape[::-1], K.dtype(feats))\n",
        "    box_confidence = K.sigmoid(feats[..., 4:5])\n",
        "    box_class_probs = K.sigmoid(feats[..., 5:])\n",
        "\n",
        "    if calc_loss == True:\n",
        "        return grid, feats, box_xy, box_wh\n",
        "    return box_xy, box_wh, box_confidence, box_class_probs\n",
        "\n",
        "\n",
        "def yolo_correct_boxes(box_xy, box_wh, input_shape, image_shape):\n",
        "    '''Get corrected boxes'''\n",
        "    box_yx = box_xy[..., ::-1]\n",
        "    box_hw = box_wh[..., ::-1]\n",
        "    input_shape = K.cast(input_shape, K.dtype(box_yx))\n",
        "    image_shape = K.cast(image_shape, K.dtype(box_yx))\n",
        "    new_shape = K.round(image_shape * K.min(input_shape/image_shape))\n",
        "    offset = (input_shape-new_shape)/2./input_shape\n",
        "    scale = input_shape/new_shape\n",
        "    box_yx = (box_yx - offset) * scale\n",
        "    box_hw *= scale\n",
        "\n",
        "    box_mins = box_yx - (box_hw / 2.)\n",
        "    box_maxes = box_yx + (box_hw / 2.)\n",
        "    boxes =  K.concatenate([\n",
        "        box_mins[..., 0:1],  # y_min\n",
        "        box_mins[..., 1:2],  # x_min\n",
        "        box_maxes[..., 0:1],  # y_max\n",
        "        box_maxes[..., 1:2]  # x_max\n",
        "    ])\n",
        "\n",
        "    # Scale boxes back to original image shape.\n",
        "    boxes *= K.concatenate([image_shape, image_shape])\n",
        "    return boxes\n",
        "\n",
        "\n",
        "def yolo_boxes_and_scores(feats, anchors, num_classes, input_shape, image_shape):\n",
        "    '''Process Conv layer output'''\n",
        "    box_xy, box_wh, box_confidence, box_class_probs = yolo_head(feats,\n",
        "        anchors, num_classes, input_shape)\n",
        "    boxes = yolo_correct_boxes(box_xy, box_wh, input_shape, image_shape)\n",
        "    boxes = K.reshape(boxes, [-1, 4])\n",
        "    box_scores = box_confidence * box_class_probs\n",
        "    box_scores = K.reshape(box_scores, [-1, num_classes])\n",
        "    return boxes, box_scores\n",
        "\n",
        "\n",
        "def yolo_eval(yolo_outputs,\n",
        "              anchors,\n",
        "              num_classes,\n",
        "              image_shape,\n",
        "              max_boxes=20,\n",
        "              score_threshold=.6,\n",
        "              iou_threshold=.5):\n",
        "    \"\"\"Evaluate YOLO model on given input and return filtered boxes.\"\"\"\n",
        "    num_layers = len(yolo_outputs)\n",
        "    anchor_mask = [[6,7,8], [3,4,5], [0,1,2]] if num_layers==3 else [[3,4,5], [1,2,3]] # default setting\n",
        "    input_shape = K.shape(yolo_outputs[0])[1:3] * 32\n",
        "    boxes = []\n",
        "    box_scores = []\n",
        "    for l in range(num_layers):\n",
        "        _boxes, _box_scores = yolo_boxes_and_scores(yolo_outputs[l],\n",
        "            anchors[anchor_mask[l]], num_classes, input_shape, image_shape)\n",
        "        boxes.append(_boxes)\n",
        "        box_scores.append(_box_scores)\n",
        "    boxes = K.concatenate(boxes, axis=0)\n",
        "    box_scores = K.concatenate(box_scores, axis=0)\n",
        "\n",
        "    mask = box_scores >= score_threshold\n",
        "    max_boxes_tensor = K.constant(max_boxes, dtype='int32')\n",
        "    boxes_ = []\n",
        "    scores_ = []\n",
        "    classes_ = []\n",
        "    for c in range(num_classes):\n",
        "        # TODO: use keras backend instead of tf.\n",
        "        class_boxes = tf.boolean_mask(boxes, mask[:, c])\n",
        "        class_box_scores = tf.boolean_mask(box_scores[:, c], mask[:, c])\n",
        "        nms_index = tf.image.non_max_suppression(\n",
        "            class_boxes, class_box_scores, max_boxes_tensor, iou_threshold=iou_threshold)\n",
        "        class_boxes = K.gather(class_boxes, nms_index)\n",
        "        class_box_scores = K.gather(class_box_scores, nms_index)\n",
        "        classes = K.ones_like(class_box_scores, 'int32') * c\n",
        "        boxes_.append(class_boxes)\n",
        "        scores_.append(class_box_scores)\n",
        "        classes_.append(classes)\n",
        "    boxes_ = K.concatenate(boxes_, axis=0)\n",
        "    scores_ = K.concatenate(scores_, axis=0)\n",
        "    classes_ = K.concatenate(classes_, axis=0)\n",
        "\n",
        "    return boxes_, scores_, classes_\n",
        "\n",
        "\n",
        "def preprocess_true_boxes(true_boxes, input_shape, anchors, num_classes):\n",
        "    '''Preprocess true boxes to training input format\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    true_boxes: array, shape=(m, T, 5)\n",
        "        Absolute x_min, y_min, x_max, y_max, class_id relative to input_shape.\n",
        "    input_shape: array-like, hw, multiples of 32\n",
        "    anchors: array, shape=(N, 2), wh\n",
        "    num_classes: integer\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    y_true: list of array, shape like yolo_outputs, xywh are reletive value\n",
        "\n",
        "    '''\n",
        "    assert (true_boxes[..., 4]<num_classes).all(), 'class id must be less than num_classes'\n",
        "    num_layers = len(anchors)//3 # default setting\n",
        "    anchor_mask = [[6,7,8], [3,4,5], [0,1,2]] if num_layers==3 else [[3,4,5], [1,2,3]]\n",
        "\n",
        "    true_boxes = np.array(true_boxes, dtype='float32')\n",
        "    input_shape = np.array(input_shape, dtype='int32')\n",
        "    boxes_xy = (true_boxes[..., 0:2] + true_boxes[..., 2:4]) // 2\n",
        "    boxes_wh = true_boxes[..., 2:4] - true_boxes[..., 0:2]\n",
        "    true_boxes[..., 0:2] = boxes_xy/input_shape[::-1]\n",
        "    true_boxes[..., 2:4] = boxes_wh/input_shape[::-1]\n",
        "\n",
        "    m = true_boxes.shape[0]\n",
        "    grid_shapes = [input_shape//{0:32, 1:16, 2:8}[l] for l in range(num_layers)]\n",
        "    y_true = [np.zeros((m,grid_shapes[l][0],grid_shapes[l][1],len(anchor_mask[l]),5+num_classes),\n",
        "        dtype='float32') for l in range(num_layers)]\n",
        "\n",
        "    # Expand dim to apply broadcasting.\n",
        "    anchors = np.expand_dims(anchors, 0)\n",
        "    anchor_maxes = anchors / 2.\n",
        "    anchor_mins = -anchor_maxes\n",
        "    valid_mask = boxes_wh[..., 0]>0\n",
        "\n",
        "    for b in range(m):\n",
        "        # Discard zero rows.\n",
        "        wh = boxes_wh[b, valid_mask[b]]\n",
        "        if len(wh)==0: continue\n",
        "        # Expand dim to apply broadcasting.\n",
        "        wh = np.expand_dims(wh, -2)\n",
        "        box_maxes = wh / 2.\n",
        "        box_mins = -box_maxes\n",
        "\n",
        "        intersect_mins = np.maximum(box_mins, anchor_mins)\n",
        "        intersect_maxes = np.minimum(box_maxes, anchor_maxes)\n",
        "        intersect_wh = np.maximum(intersect_maxes - intersect_mins, 0.)\n",
        "        intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
        "        box_area = wh[..., 0] * wh[..., 1]\n",
        "        anchor_area = anchors[..., 0] * anchors[..., 1]\n",
        "        iou = intersect_area / (box_area + anchor_area - intersect_area)\n",
        "\n",
        "        # Find best anchor for each true box\n",
        "        best_anchor = np.argmax(iou, axis=-1)\n",
        "\n",
        "        for t, n in enumerate(best_anchor):\n",
        "            for l in range(num_layers):\n",
        "                if n in anchor_mask[l]:\n",
        "                    i = np.floor(true_boxes[b,t,0]*grid_shapes[l][1]).astype('int32')\n",
        "                    j = np.floor(true_boxes[b,t,1]*grid_shapes[l][0]).astype('int32')\n",
        "                    k = anchor_mask[l].index(n)\n",
        "                    c = true_boxes[b,t, 4].astype('int32')\n",
        "                    y_true[l][b, j, i, k, 0:4] = true_boxes[b,t, 0:4]\n",
        "                    y_true[l][b, j, i, k, 4] = 1\n",
        "                    y_true[l][b, j, i, k, 5+c] = 1\n",
        "\n",
        "    return y_true\n",
        "\n",
        "\n",
        "def box_iou(b1, b2):\n",
        "    '''Return iou tensor\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    b1: tensor, shape=(i1,...,iN, 4), xywh\n",
        "    b2: tensor, shape=(j, 4), xywh\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    iou: tensor, shape=(i1,...,iN, j)\n",
        "\n",
        "    '''\n",
        "\n",
        "    # Expand dim to apply broadcasting.\n",
        "    b1 = K.expand_dims(b1, -2)\n",
        "    b1_xy = b1[..., :2]\n",
        "    b1_wh = b1[..., 2:4]\n",
        "    b1_wh_half = b1_wh/2.\n",
        "    b1_mins = b1_xy - b1_wh_half\n",
        "    b1_maxes = b1_xy + b1_wh_half\n",
        "\n",
        "    # Expand dim to apply broadcasting.\n",
        "    b2 = K.expand_dims(b2, 0)\n",
        "    b2_xy = b2[..., :2]\n",
        "    b2_wh = b2[..., 2:4]\n",
        "    b2_wh_half = b2_wh/2.\n",
        "    b2_mins = b2_xy - b2_wh_half\n",
        "    b2_maxes = b2_xy + b2_wh_half\n",
        "\n",
        "    intersect_mins = K.maximum(b1_mins, b2_mins)\n",
        "    intersect_maxes = K.minimum(b1_maxes, b2_maxes)\n",
        "    intersect_wh = K.maximum(intersect_maxes - intersect_mins, 0.)\n",
        "    intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
        "    b1_area = b1_wh[..., 0] * b1_wh[..., 1]\n",
        "    b2_area = b2_wh[..., 0] * b2_wh[..., 1]\n",
        "    iou = intersect_area / (b1_area + b2_area - intersect_area)\n",
        "\n",
        "    return iou\n",
        "\n",
        "\n",
        "def yolo_loss(args, anchors, num_classes, ignore_thresh=.5, print_loss=False):\n",
        "    '''Return yolo_loss tensor\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    yolo_outputs: list of tensor, the output of yolo_body or tiny_yolo_body\n",
        "    y_true: list of array, the output of preprocess_true_boxes\n",
        "    anchors: array, shape=(N, 2), wh\n",
        "    num_classes: integer\n",
        "    ignore_thresh: float, the iou threshold whether to ignore object confidence loss\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    loss: tensor, shape=(1,)\n",
        "\n",
        "    '''\n",
        "    num_layers = len(anchors)//3 # default setting\n",
        "    yolo_outputs = args[:num_layers]\n",
        "    y_true = args[num_layers:]\n",
        "    anchor_mask = [[6,7,8], [3,4,5], [0,1,2]] if num_layers==3 else [[3,4,5], [1,2,3]]\n",
        "    input_shape = K.cast(K.shape(yolo_outputs[0])[1:3] * 32, K.dtype(y_true[0]))\n",
        "    grid_shapes = [K.cast(K.shape(yolo_outputs[l])[1:3], K.dtype(y_true[0])) for l in range(num_layers)]\n",
        "    loss = 0\n",
        "    m = K.shape(yolo_outputs[0])[0] # batch size, tensor\n",
        "    mf = K.cast(m, K.dtype(yolo_outputs[0]))\n",
        "\n",
        "    for l in range(num_layers):\n",
        "        object_mask = y_true[l][..., 4:5]\n",
        "        true_class_probs = y_true[l][..., 5:]\n",
        "\n",
        "        grid, raw_pred, pred_xy, pred_wh = yolo_head(yolo_outputs[l],\n",
        "             anchors[anchor_mask[l]], num_classes, input_shape, calc_loss=True)\n",
        "        pred_box = K.concatenate([pred_xy, pred_wh])\n",
        "\n",
        "        # Darknet raw box to calculate loss.\n",
        "        raw_true_xy = y_true[l][..., :2]*grid_shapes[l][::-1] - grid\n",
        "        raw_true_wh = K.log(y_true[l][..., 2:4] / anchors[anchor_mask[l]] * input_shape[::-1])\n",
        "        raw_true_wh = K.switch(object_mask, raw_true_wh, K.zeros_like(raw_true_wh)) # avoid log(0)=-inf\n",
        "        box_loss_scale = 2 - y_true[l][...,2:3]*y_true[l][...,3:4]\n",
        "\n",
        "        # Find ignore mask, iterate over each of batch.\n",
        "        ignore_mask = tf.TensorArray(K.dtype(y_true[0]), size=1, dynamic_size=True)\n",
        "        object_mask_bool = K.cast(object_mask, 'bool')\n",
        "        def loop_body(b, ignore_mask):\n",
        "            true_box = tf.boolean_mask(y_true[l][b,...,0:4], object_mask_bool[b,...,0])\n",
        "            iou = box_iou(pred_box[b], true_box)\n",
        "            best_iou = K.max(iou, axis=-1)\n",
        "            ignore_mask = ignore_mask.write(b, K.cast(best_iou<ignore_thresh, K.dtype(true_box)))\n",
        "            return b+1, ignore_mask\n",
        "        _, ignore_mask = K.control_flow_ops.while_loop(lambda b,*args: b<m, loop_body, [0, ignore_mask])\n",
        "        ignore_mask = ignore_mask.stack()\n",
        "        ignore_mask = K.expand_dims(ignore_mask, -1)\n",
        "\n",
        "        # K.binary_crossentropy is helpful to avoid exp overflow.\n",
        "        xy_loss = object_mask * box_loss_scale * K.binary_crossentropy(raw_true_xy, raw_pred[...,0:2], from_logits=True)\n",
        "        wh_loss = object_mask * box_loss_scale * 0.5 * K.square(raw_true_wh-raw_pred[...,2:4])\n",
        "        confidence_loss = object_mask * K.binary_crossentropy(object_mask, raw_pred[...,4:5], from_logits=True)+ \\\n",
        "            (1-object_mask) * K.binary_crossentropy(object_mask, raw_pred[...,4:5], from_logits=True) * ignore_mask\n",
        "        class_loss = object_mask * K.binary_crossentropy(true_class_probs, raw_pred[...,5:], from_logits=True)\n",
        "\n",
        "        xy_loss = K.sum(xy_loss) / mf\n",
        "        wh_loss = K.sum(wh_loss) / mf\n",
        "        confidence_loss = K.sum(confidence_loss) / mf\n",
        "        class_loss = K.sum(class_loss) / mf\n",
        "        loss += xy_loss + wh_loss + confidence_loss + class_loss\n",
        "        if print_loss:\n",
        "            loss = tf.Print(loss, [loss, xy_loss, wh_loss, confidence_loss, class_loss, K.sum(ignore_mask)], message='loss: ')\n",
        "    return loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31bV1dfn6squ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "8205a5a8-0173-4c99-c1d2-d1d88a0b0759"
      },
      "source": [
        "import sys\n",
        "import argparse\n",
        "from yolo import YOLO, detect_video\n",
        "from PIL import Image\n",
        "\n",
        "def detect_img(yolo):\n",
        "    while True:\n",
        "        img = input('img_50.jpg')\n",
        "        try:\n",
        "            image = Image.open(img)\n",
        "        except:\n",
        "            print('Open Error! Try again!')\n",
        "            continue\n",
        "        else:\n",
        "            r_image = yolo.detect_image(image)\n",
        "            r_image.show()\n",
        "    yolo.close_session()\n",
        "\n",
        "FLAGS = None\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # class YOLO defines the default value, so suppress any default here\n",
        "    parser = argparse.ArgumentParser(argument_default=argparse.SUPPRESS)\n",
        "    '''\n",
        "    Command line options\n",
        "    '''\n",
        "    parser.add_argument(\n",
        "        '--model', type=str,\n",
        "        help='path to model weight file, default ' + YOLO.get_defaults(\"model.py\")\n",
        "    )\n",
        "\n",
        "    parser.add_argument(\n",
        "        '--anchors', type=str,\n",
        "        help='path to anchor definitions, default ' + YOLO.get_defaults(\"yolo_anchors.txt\")\n",
        "    )\n",
        "\n",
        "    parser.add_argument(\n",
        "        '--classes', type=str,\n",
        "        help='path to class definitions, default ' + YOLO.get_defaults(\"voc_classes.txt\")\n",
        "    )\n",
        "\n",
        "    parser.add_argument(\n",
        "        '--gpu_num', type=int,\n",
        "        help='Number of GPU to use, default ' + str(YOLO.get_defaults(\"1\"))\n",
        "    )\n",
        "\n",
        "    parser.add_argument(\n",
        "        '--image', default=False, action=True,\n",
        "        help='Image detection mode, will ignore all positional arguments'\n",
        "    )\n",
        "    '''\n",
        "    Command line positional arguments -- for video detection mode\n",
        "    '''\n",
        "    parser.add_argument(\n",
        "        \"--input\", nargs='?', type=str,required=False,default='20200313-200602.avi',\n",
        "        help = \"Video input path\"\n",
        "    )\n",
        "\n",
        "    parser.add_argument(\n",
        "        \"--output\", nargs='?', type=str, default=\"\",\n",
        "        help = \"[Optional] Video output path\"\n",
        "    )\n",
        "\n",
        "    FLAGS = parser.parse_args()\n",
        "\n",
        "    if FLAGS.image:\n",
        "        \"\"\"\n",
        "        Image detection mode, disregard any remaining command line arguments\n",
        "        \"\"\"\n",
        "        print(\"Image detection mode\")\n",
        "        if \"input\" in FLAGS:\n",
        "            print(\" Ignoring remaining command line arguments: \" + FLAGS.input + \",\" + FLAGS.output)\n",
        "        detect_img(YOLO(**vars(FLAGS)))\n",
        "    elif \"input\" in FLAGS:\n",
        "        detect_video(YOLO(**vars(FLAGS)), FLAGS.input, FLAGS.output)\n",
        "    else:\n",
        "        print(\"Must specify at least video_input_path.  See usage with --help.\")\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: ipykernel_launcher.py [-h] [--model MODEL] [--anchors ANCHORS]\n",
            "                             [--classes CLASSES] [--gpu_num GPU_NUM] [--image]\n",
            "                             [--input [INPUT]] [--output [OUTPUT]]\n",
            "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-8bc12327-70c3-4c80-8386-c9cc156cdade.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}